{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##Optimization using Gradient Descent\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "LyUoTvcZLnnI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####*Regression at a glance*\n",
        "<center><img src='https://drive.google.com/uc?id=1GQX75_ETwGQ4XRBAYVO1fLabkj5LKExr' width=\"600\"></center>\n",
        "\n",
        "\n",
        "- Red line is our regression line which fitting our datapoints.\n",
        "- Error is difference of actual and predicted value.\n",
        "  - $e_i = y_i - y_{pred}$\n",
        "- Now taking squares of error terms and adding them all up makes our **sum of squared errors**\n",
        "\n"
      ],
      "metadata": {
        "id": "YtNiKYlhMd2R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *Slope of Regression line*\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1sOhabyWlsTpfu-tcWwVa4oPfPNTsIyJ9' width=\"800\" ></center>\n",
        "\n",
        "\n",
        "- Our slope of a line is the rate of change of y with respect to x.\n",
        "  - $\\frac{{\\Delta}y}{{\\Delta}x}$ = slope"
      ],
      "metadata": {
        "id": "chomr8onNn4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *Zero Slope*\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1egN5_s8MXKJRir1YzLaMmQNus6E6wTwa' width=\"500\" >\n",
        "\n",
        "\n",
        "- Consider this eqn: $y= x^2$\n",
        "- On the plot of above eqn we three point A,B and C\n",
        "  - Point A : As x inc, y also inc that means slope is +tve\n",
        "  - Point B : As x move towards positive, y dec, that slope is -tve\n",
        "  - Point C : These no change in y, hence slope = 0\n",
        "\n",
        "- So we get the minimum value of our function, when our slope is zero."
      ],
      "metadata": {
        "id": "ytY81KBcPDWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *Loss function*\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1YHsn786Tus6gzm3I2cKD2p3uctKmCaez' width=\"800\"></center>\n",
        "\n",
        "\n",
        "- Now our loss function is $L=\\sum(y-y_{pred})^2$\n",
        "  - If we observe, it is same as $y=x^2$\n",
        "\n",
        "- We started randomly and found our loss at point A is high.\n",
        "- We come down at point B, and got slight reduction in our **loss**\n",
        "- At point C, the line fitting better on data.\n",
        "- At point D, we have perfect fit because our loss is minimized and our slope is zero."
      ],
      "metadata": {
        "id": "BW47d471AA8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *How gradient Desecent works(intuition)*\n",
        "<center><img src='https://drive.google.com/uc?id=15cLnbwuM6GH73pGh2YtlM6g40Hmb-q3L' width=\"800\" \"></center>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Our loss $L$ is function of $w$, as we change these values, the loss varies.\n",
        "- Right Side:\n",
        "  - When we start minimizing our loss, we start with random values of $w$\n",
        "  - Suppose the first random value was $w_1$, at this point our loss is high, in order to reduce loss, we have to move left side.\n",
        "  - So the $w_{new}$ is calculated gradient descent formula\n",
        "  - After each iteration we get new $w$ untill our loss is minimized.\n",
        "\n",
        "\n",
        "- Left side:\n",
        "  - If we start with left side, to reduce loss we have to move right side.\n",
        "  - The remaining process is same"
      ],
      "metadata": {
        "id": "A_c3CqQZII68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Content-based Filtering -\n",
        "---"
      ],
      "metadata": {
        "id": "nYOS350RFY6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### Q. How can we overcome cold start problem?\n",
        "\n",
        "Consider the case of a new user. Even though we do not have any information regarding this user's interactions with different items, we do have other additional information about this new user. Such as,\n",
        "\n",
        "- **Location**\n",
        " - This can be used to get an idea of the items used / purchased by other users in that area.\n",
        " - On Swiggy, people from Uttar Pradesh are more likely to order Chote Bhature rather than Idli Sambhar.\n",
        "\n",
        "- **Gender**\n",
        " - Useful in recommending clothes and accessories.\n",
        " - Platforms like Myntra and Ajio recommend their products based on gender of the customer.\n",
        "\n",
        "- **Age**\n",
        "  - An adult would like to watch news or sports on TV, whereas a child would prefer watching cartoons.\n",
        "  - Netflix users from different age groups would prefer to watch movies or web series of different genre.\n",
        "\n",
        "- **Device being used to access the platform**\n",
        " - We can assume that an user using Apple Macbook would have more spending power than a user using a cheap Chinese smartphone.\n",
        "\n",
        "We store all this information and then use **user-user similarity** on it to generate recommendations.\n",
        "\n",
        "This is known as **user-user similarity based content filtering**.\n"
      ],
      "metadata": {
        "id": "dc2SsaRvidX5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### Q. Do we have any kind of additional information that can be used in case of a new item cold start?\n",
        "\n",
        "Yes.\n",
        "\n",
        "Consider that there is a new product on Flipkart, though there is no data about user ratings, we still have additional information like:-\n",
        "- **Product Description**\n",
        "- **Price Range**\n",
        "- **Product Category**\n",
        "\n",
        "We store all this information and then use **item-item similarity** on it, and recommend accordingly. Hence this is called **item-item similarity based content filtering**.\n",
        "\n",
        "We can recommend this new item to those users who bought similar items from the same categories until we have sufficient information. These additional information is known as **metadata**.\n",
        "\n",
        "This process of finding user-user or item-item similarities, using metadata in order to recommend items to users is called **Content-based Recommendation system**.\n"
      ],
      "metadata": {
        "id": "DgJcM6hhkI9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1XFumM8eiDcQXOS37pGCJAgAV4F_TVPQP' width=\"900\" height=\"550\">\n"
      ],
      "metadata": {
        "id": "FL9GFqBE3QUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Advantages & Disadvantages -\n",
        "---"
      ],
      "metadata": {
        "id": "gOuXJJydlxkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### Q. What are some advantages and disadvantages of collaborative filtering?\n",
        "\n",
        "**Advantages**\n",
        "- Domain knowledge is not necessary.\n",
        "- **Serendipity**\n",
        " - The model can help users discover new interests.\n",
        "\n",
        "**Disadvantages**\n",
        "- Fails in case of a cold start.\n",
        "\n",
        "</br>\n",
        "\n",
        "> #### Q. What are some advantages and disadvantages of content based filtering?\n",
        "\n",
        "**Advantages**\n",
        "- The model doesn't need any data about other users.\n",
        "- It is **easier to scale** to a large number of users.\n",
        "- The model can capture the specific interests of a user, and can recommend niche items that very few other users are interested in.\n",
        "\n",
        "**Disadvantages**\n",
        "- This technique requires a lot of domain knowledge.\n",
        "- It always recommends items related to the same categories, and never recommend anything from other categories.\n"
      ],
      "metadata": {
        "id": "-6ONwLEnlrFI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Matrix Factorization\n",
        "---"
      ],
      "metadata": {
        "id": "8I52EnFPe5n6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This idea of using Matrix Factorization for Recommender systems was introduced around 2008-2009, during the Netflix prize competition.\n",
        "\n",
        "Recall the concept of factorization in algebra, that you'd have studied in school.\n",
        "\n",
        "As per this concept, we can write a number as products of it's **factors**. For example, $6 = 2 * 3$.\n",
        "\n",
        "Recall that we have our $n$ x $m$ matrix A.\n",
        "\n",
        "Let's try to expand this concept for matrices by decomposing it as a product of two other matrices:-\n",
        "\n",
        "A = B . C\n",
        "\n",
        "This is called as **Matrix Factorization (MF) / Matrix Decomposition**"
      ],
      "metadata": {
        "id": "LRAUDx_pof_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=119QI7PD4NTsdSUF4Dca1D_5MtCaAwFS-' width=\"900\" height=\"400\">\n"
      ],
      "metadata": {
        "id": "__-cMM105_F_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### Q. How is the concept of MF relevant to Recommender systems?\n",
        "\n",
        "Recall that our matrix `A` is very sparse, meaning that there are a lot of missing values.\n",
        "\n",
        "* If we could somehow get an estimate of these values based on the ones that we have, we would get an idea of how each user would rate each item.\n",
        "\n",
        "* This would be very helpful in recommending new items to the users.\n",
        "\n",
        "* This technique of utilising the available values to complete the sparse matrix is called **Matrix Completion**.\n",
        "\n",
        "* One way of solving this problem is by **Matrix Factorization**."
      ],
      "metadata": {
        "id": "snwn-oXFohTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Matrix Factorization for Collaborative Filtering\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1i0EMgeHzhRx8A92blHLGpR3qUGqbV36X'  height=\"500\"> </center>\n",
        "\n",
        "\n",
        "- userID 14 has rated movieID 49 as 5 stars\n",
        "- userID 29 has rated movieID 57 as 5 stars\n",
        "\n",
        "- There are some cells missing as well. userID 212 has rated movieID 27 but not movieID 49.\n",
        "- If somehow we  predict these empty cells and if the rating comes out to be good for let's userID 212 , then we would recommend this to user 212.\n",
        "\n",
        "####Q. How are we going to predict these cells?\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1i0V9H9HJ66m0SOmKae1kI1jeaw8pz1nm' height=\"600\"> </center>\n",
        "\n",
        "- We factorise our matrix **A** into two small matices **B** and **C**\n",
        "\n",
        "- In matrix B, we come up with features, let's say we represent user14 with five numerical features.\n",
        "- In matrix C, we represent movieID 27 with also 5 numerical features.\n",
        "- These features are random numbers only.\n",
        "- In a similar manner both B and C matrices are filled.\n",
        "\n",
        "###### Why only 5 features ? -->  This is our hyperparameter.\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=18xn6lv9OKlfQ-0ksLO8s3_VTRIKoKJOs' width=\"850\" height=\"500\"> </center>\n",
        "\n",
        "\n",
        "- These features for user and movies could be matrix multiplied and would give us some value in $\\hat{A}$ matrix\n",
        "\n",
        "- Similarly we would fill all values of $\\hat{A}$ matrix  using multiplication of userID features to its corresponding movieID features."
      ],
      "metadata": {
        "id": "Dm7yPT5aBSNE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1kYcimB7Q4vM1nLJJtmWPuwlA1wHp-EcW' height=\"500\"> </center>\n",
        "\n",
        "- Now we have matrix A and matrix $\\hat{A}$. The corresponding values for cells in the matrices are subtracted to know the Error.\n",
        "- The optimization takes place by minimizing the error using same approach of Gradient descent.\n",
        "\n",
        "- Using this approach after each iteration values of B and C matrices are updated untill error is minimized.\n",
        "\n",
        "- Once error is minimized B & C are again multiplied to get predicted A matrix, here we have no empty cells.\n",
        "- These non- empty are predicted are ratings"
      ],
      "metadata": {
        "id": "cO0eKg0gG2gG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How do you calculate error when some cells empty in A matrix?\n",
        "\n",
        "- We do not take in account empty cells for calculating errors."
      ],
      "metadata": {
        "id": "3wCQHEoNOpZ2"
      }
    }
  ]
}